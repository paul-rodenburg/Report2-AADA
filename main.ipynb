{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "223d27f6-6f96-4481-b7fa-364f1110c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from point import ClusterPoint as CP\n",
    "from boxgraph import BoxGraph\n",
    "from dbscan_boxgraph_implementation import find_core_points, compute_cluster_cores, assign_border_points\n",
    "\n",
    "from point import Point, ClusterPoint\n",
    "from square import Square\n",
    "from node import Node\n",
    "\n",
    "from db_scan import *\n",
    "from dataset import *\n",
    "from range_query import RangeQuery, LinearQuery\n",
    "from dbscan_quadtree_implentation import QuadTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8296dcb8-4530-4f3d-b88b-439e0faacbc6",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7726a15-8145-41ea-b8a5-83bdd32878f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_latex_table(df, caption, label):\n",
    "    df = df.round(5)\n",
    "    from io import StringIO\n",
    "\n",
    "    # Start building LaTeX table\n",
    "    output = StringIO()\n",
    "    num_cols = len(df.columns)\n",
    "\n",
    "    # Begin table environment\n",
    "    output.write(\"\\\\begin{table}[H]\\n\")\n",
    "    output.write(\"    \\\\centering\\n\")\n",
    "    output.write(\"    \\\\footnotesize\\n\")\n",
    "    output.write(\"    \\\\renewcommand{\\\\arraystretch}{1.3} % Adds row height for better readability\\n\")\n",
    "    \n",
    "    # Column format: first column left-aligned, rest flexible (X)\n",
    "    col_format = \"|l\" + \"|X\" * (num_cols - 1) + \"|\"\n",
    "    output.write(f\"    \\\\begin{{tabularx}}{{\\\\textwidth}}{{{col_format}}}\\n\")\n",
    "    output.write(\"        \\\\hline\\n\")\n",
    "    \n",
    "    # Column headers\n",
    "    # headers = \" & \".join([f\"\\\\textbf{{{col.replace('_', '\\_')}}}\" for col in df.columns]) + \" \\\\\\\\\"\n",
    "    cols = [col.replace('_', '\\_') for col in df.columns]\n",
    "    headers = \" & \".join([f\"\\\\textbf{{{col}}}\" for col in cols]) + \" \\\\\\\\\"\n",
    "    output.write(f\"        {headers}\\n\")\n",
    "    output.write(\"         \\\\hline\\n\")\n",
    "    \n",
    "    # Data rows\n",
    "    for _, row in df.iterrows():\n",
    "        values = \" & \".join(str(cell).replace('_', '\\_').replace('%', '\\%') for cell in row) + \" \\\\\\\\\"\n",
    "        output.write(f\"         {values}\\n\")\n",
    "    \n",
    "    output.write(\"         \\\\hline\\n\")\n",
    "    output.write(\"    \\\\end{tabularx}\\n\")\n",
    "    output.write(f\"    \\\\caption{{{caption}}}\\n\")\n",
    "    output.write(f\"    \\\\label{{{label}}}\\n\")\n",
    "    output.write(\"\\\\end{table}\\n\")\n",
    "\n",
    "    return output.getvalue()\n",
    "\n",
    "def df_to_latex_table2(df, caption, label):\n",
    "    df = df.round(5)\n",
    "    from io import StringIO\n",
    "\n",
    "    output = StringIO()\n",
    "    num_cols = len(df.columns)\n",
    "\n",
    "    # Begin LaTeX table\n",
    "    output.write(\"\\\\begin{table}[H]\\n\")\n",
    "    output.write(\"    \\\\centering\\n\")\n",
    "    output.write(\"    \\\\footnotesize\\n\")\n",
    "    output.write(\"    \\\\renewcommand{\\\\arraystretch}{1.3} % Adds row height for better readability\\n\")\n",
    "\n",
    "    # Use tabularx for flexible-width columns\n",
    "    col_format = \"|l\" + \"|X\" * (num_cols - 1) + \"|\"\n",
    "    output.write(f\"    \\\\begin{{tabularx}}{{\\\\textwidth}}{{{col_format}}}\\n\")\n",
    "    output.write(\"        \\\\hline\\n\")\n",
    "\n",
    "    # Header row\n",
    "    headers = [f\"\\\\textbf{{{str(col).replace('_', '\\\\_')}}}\" for col in df.columns]\n",
    "    output.write(\"        \" + \" & \".join(headers) + \" \\\\\\\\\\n\")\n",
    "    output.write(\"        \\\\hline\\n\")\n",
    "\n",
    "    # Data rows\n",
    "    for _, row in df.iterrows():\n",
    "        values = [\n",
    "            str(cell).replace('_', '\\\\_').replace('%', '\\\\%') \n",
    "            for cell in row\n",
    "        ]\n",
    "        output.write(\"        \" + \" & \".join(values) + \" \\\\\\\\\\n\")\n",
    "\n",
    "    output.write(\"        \\\\hline\\n\")\n",
    "    output.write(\"    \\\\end{tabularx}\\n\")\n",
    "    output.write(f\"    \\\\caption{{{caption}}}\\n\")\n",
    "    output.write(f\"    \\\\label{{{label}}}\\n\")\n",
    "    output.write(\"\\\\end{table}\\n\")\n",
    "\n",
    "    return output.getvalue()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b357c5c7-5f3e-44ec-8368-d67da0d76265",
   "metadata": {},
   "source": [
    "## DBSCAN Algorithm Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "717c70a1-896b-46db-a8fc-256f677d8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dbscan_linear(points, eps, min_pts):\n",
    "    # ─── Step 1: Convert raw coordinates to ClusterPoint objects ───\n",
    "    cp_points = [ClusterPoint(2, [float(x), float(y)]) for x, y in points]\n",
    "\n",
    "    # ─── Step 2: Initialize linear range query (no spatial structure) ───\n",
    "    start_init = time.perf_counter()\n",
    "    query_obj = LinearQuery(cp_points)  # minimal setup time\n",
    "    init_time = time.perf_counter() - start_init\n",
    "\n",
    "    # ─── Step 3: Run the DBSCAN clustering algorithm ───\n",
    "    start_query = time.perf_counter()\n",
    "    nr_clusters = find_clustering(cp_points, eps, min_pts, query_obj)\n",
    "    query_time = time.perf_counter() - start_query\n",
    "\n",
    "    # ─── Step 4: Collect labels and timings ───\n",
    "    labels = [p.cluster_label for p in cp_points]\n",
    "    return labels, {\"init\": init_time, \"range_queries\": query_time}\n",
    "\n",
    "def run_dbscan_quadtree(points, eps, min_pts):\n",
    "    # ─── Step 1: Wrap raw points in ClusterPoint objects ───\n",
    "    cp_points = [ClusterPoint(2, [float(x), float(y)]) for x, y in points]\n",
    "\n",
    "    # ─── Step 2: Setup timing for quadtree creation ───\n",
    "    start_init = time.perf_counter()\n",
    "    query_obj = QuadTree(cp_points)  # this builds the tree\n",
    "    init_time = time.perf_counter() - start_init\n",
    "\n",
    "    # ─── Step 3: Run clustering using the quadtree ───\n",
    "    start_query = time.perf_counter()\n",
    "    nr_clusters = find_clustering(cp_points, eps, min_pts, query_obj)\n",
    "    query_time = time.perf_counter() - start_query\n",
    "\n",
    "    # ─── Step 4: Return cluster labels and timing ───\n",
    "    labels = [p.cluster_label for p in cp_points]\n",
    "    return labels, {\"init\": init_time, \"range_queries\": query_time}\n",
    "\n",
    "def run_dbscan_boxgraph(points, eps, min_pts):\n",
    "    # ─── Step 1: Convert numpy points → ClusterPoint objects ───\n",
    "    cp_points = [CP(2, [float(x), float(y)]) for x, y in points]\n",
    "    n = len(cp_points)\n",
    "    d = 2\n",
    "\n",
    "    # ─── Step 2: Build BoxGraph ───\n",
    "    start_init = time.perf_counter()\n",
    "    bg = BoxGraph(n, d, eps, min_pts, cp_points)\n",
    "    init_time = time.perf_counter() - start_init\n",
    "\n",
    "    # ─── Step 3: Clustering steps ───\n",
    "    start_query = time.perf_counter()\n",
    "    find_core_points(bg)\n",
    "    compute_cluster_cores(bg)\n",
    "    assign_border_points(bg)\n",
    "    query_time = time.perf_counter() - start_query\n",
    "\n",
    "    # ─── Step 4: Return cluster labels and timings ───\n",
    "    labels = [p.cluster_label for p in cp_points]\n",
    "    return labels, {\"init\": init_time, \"range_queries\": query_time}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750d95ba-5f8f-44b4-b5d1-ade1ddecb0b8",
   "metadata": {},
   "source": [
    "## Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a35f10c-c13d-4b71-a714-28eee30eec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing results. This will take a while (around 5 mins)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing : 100%|█| 18/18 [04:33<00:00, 25.97s/it, name=boxgraph; N=10000; noise"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method            boxgraph     linear   quadtree\n",
      "noise_frac N                                    \n",
      "0.0        1000   0.007882   0.731622   0.525113\n",
      "           10000  0.127895  76.092138  25.095162\n",
      "0.2        1000   0.007264   0.684223   0.369970\n",
      "           10000  0.107962  74.922418  19.057611\n",
      "0.5        1000   0.006408   0.636198   0.248127\n",
      "           10000  0.095874  64.084202  11.140647\n"
     ]
    }
   ],
   "source": [
    "# First check if you already have the results so you can load them (saves a lot of time)\n",
    "if os.path.isfile('results.csv'):\n",
    "    load_results = input('results.csv is available. Do you want to load it (saves time)? [y/n]')\n",
    "    if load_results.strip().lower() == 'y':\n",
    "        df = pd.read_csv('results.csv')\n",
    "        LOADED = True\n",
    "    else:\n",
    "        LOADED = False\n",
    "else:\n",
    "    LOADED = False\n",
    "\n",
    "if not LOADED:  # Check if the csv file with the results was loaded, if not then compute the results\n",
    "    print(\"Computing results. This will take a while (around 5 mins)...\")\n",
    "    \n",
    "    eps = 0.5\n",
    "    min_pts = 5\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Sizes and noise levels to test\n",
    "    # grid_N = [1_000, 10_000, 100_000, 500_000]\n",
    "    grid_N = [1_000, 10_000]\n",
    "    noise_ratios = [0.0, 0.2, 0.5]    # fraction of points uniformly at random\n",
    "    \n",
    "    results = []\n",
    "    total = len(grid_N) * len(noise_ratios) * 3  # 3 is the number of methods used\n",
    "\n",
    "    p_bar = tqdm(desc='Computing ', total=total)\n",
    "    for N in grid_N:\n",
    "        for noise_frac in noise_ratios:\n",
    "            n_noise = int(N * noise_frac)\n",
    "            n_clusters = N - n_noise\n",
    "            # Generate clustered data\n",
    "            Xc, _ = make_blobs(n_samples=n_clusters,\n",
    "                               centers=[(-5,-5),(5,5),(5,-5),(-5,5)],\n",
    "                               cluster_std=1.0, random_state=42)\n",
    "            # Generate uniform noise\n",
    "            Xn = np.random.uniform(low=-10, high=10, size=(n_noise, 2))\n",
    "            X = np.vstack([Xc, Xn])\n",
    "    \n",
    "            for name, runner in [\n",
    "                (\"linear\",    run_dbscan_linear),\n",
    "                (\"quadtree\",  run_dbscan_quadtree),\n",
    "                (\"boxgraph\",  run_dbscan_boxgraph),\n",
    "            ]:\n",
    "                p_bar.update(1)\n",
    "                p_bar.set_postfix_str(f'name={name}; N={N}; noise={noise_frac}')\n",
    "                labels, timing = runner(X, eps, min_pts)\n",
    "                total_time = timing[\"init\"] + timing[\"range_queries\"]\n",
    "                results.append({\n",
    "                    \"method\": name,\n",
    "                    \"N\": N,\n",
    "                    \"noise_frac\": noise_frac,\n",
    "                    \"init_time\": timing[\"init\"],\n",
    "                    \"query_time\": timing[\"range_queries\"],\n",
    "                    \"total_time\": total_time\n",
    "                })\n",
    "    \n",
    "    # Aggregate into DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv('results.csv')\n",
    "\n",
    "# Print summary table\n",
    "print(df.groupby([\"method\",\"noise_frac\",\"N\"])[\"total_time\"].mean().unstack(\"method\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f938c6-3b59-4e72-813e-93c3f1505288",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e57e04c2-88db-4807-b972-a51962bfc97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# for method in df[\"method\"].unique():\n",
    "#     sub = df[df[\"method\"] == method]\n",
    "#     ax.plot(sub[\"N\"], sub[\"total_time\"], marker='o', label=method)\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_yscale('log')\n",
    "# ax.set_xlabel(\"Number of points N\")\n",
    "# ax.set_ylabel(\"Average total runtime (s)\")\n",
    "# ax.legend()\n",
    "# ax.set_title(f\"DBSCAN scaling, noise={noise_ratios}\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27646768-e426-4eb2-bc51-c8c681e9705a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\footnotesize\n",
      "    \\renewcommand{\\arraystretch}{1.3} % Adds row height for better readability\n",
      "    \\begin{tabularx}{\\textwidth}{|l|X|X|X|X|X|}\n",
      "        \\hline\n",
      "        \\textbf{method} & \\textbf{N} & \\textbf{noise\\_frac} & \\textbf{init\\_time} & \\textbf{query\\_time} & \\textbf{total\\_time} \\\\\n",
      "        \\hline\n",
      "        linear & 1000 & 0.0 & 0.0 & 0.73162 & 0.73162 \\\\\n",
      "        quadtree & 1000 & 0.0 & 0.00476 & 0.52035 & 0.52511 \\\\\n",
      "        boxgraph & 1000 & 0.0 & 0.00153 & 0.00635 & 0.00788 \\\\\n",
      "        linear & 1000 & 0.2 & 0.0 & 0.68422 & 0.68422 \\\\\n",
      "        quadtree & 1000 & 0.2 & 0.00476 & 0.36521 & 0.36997 \\\\\n",
      "        boxgraph & 1000 & 0.2 & 0.00184 & 0.00543 & 0.00726 \\\\\n",
      "        linear & 1000 & 0.5 & 0.0 & 0.6362 & 0.6362 \\\\\n",
      "        quadtree & 1000 & 0.5 & 0.00451 & 0.24362 & 0.24813 \\\\\n",
      "        boxgraph & 1000 & 0.5 & 0.00188 & 0.00453 & 0.00641 \\\\\n",
      "        linear & 10000 & 0.0 & 0.0 & 76.09214 & 76.09214 \\\\\n",
      "        quadtree & 10000 & 0.0 & 0.08422 & 25.01095 & 25.09516 \\\\\n",
      "        boxgraph & 10000 & 0.0 & 0.0082 & 0.1197 & 0.1279 \\\\\n",
      "        linear & 10000 & 0.2 & 0.0 & 74.92242 & 74.92242 \\\\\n",
      "        quadtree & 10000 & 0.2 & 0.09953 & 18.95808 & 19.05761 \\\\\n",
      "        boxgraph & 10000 & 0.2 & 0.0106 & 0.09736 & 0.10796 \\\\\n",
      "        linear & 10000 & 0.5 & 0.0 & 64.0842 & 64.0842 \\\\\n",
      "        quadtree & 10000 & 0.5 & 0.08526 & 11.05539 & 11.14065 \\\\\n",
      "        boxgraph & 10000 & 0.5 & 0.01311 & 0.08276 & 0.09587 \\\\\n",
      "        \\hline\n",
      "    \\end{tabularx}\n",
      "    \\caption{Results for different DBSCAN algorithms, N, and noise ratio}\n",
      "    \\label{tab:results_main}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = df_to_latex_table2(df, 'Results for different DBSCAN algorithms, N, and noise ratio', 'tab:results_main')\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
